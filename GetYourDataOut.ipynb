{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b89edcb3-f43e-4e46-bdac-9441a4c40ab1","showTitle":false,"title":""}},"outputs":[],"source":["#  Pip install\n","!pip install pandas\n","!pip install azure-storage-file-datalake"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c71a11eb-7e71-42fc-82a2-b6f1bb94e67f","showTitle":false,"title":""}},"outputs":[],"source":["STORAGE_ACCOUNT                               = \"ChangeMe\"                    \n","TENANT_ID                                     = \"ChangeMe\"\n","SCOPE_NAME                                    = \"ChangeMe\"\n","AAD_APPID                                     = \"ChangeMe\"\n","WORKSPACE_ID                                  = \"ChangeMe\"\n","SERVICE_CREDENTIAL_KEY_NAME_STORAGE_KEY       = \"ChangeMe\"\n","SERVICE_CREDENTIAL_KEY_NAME_DATALAKE          = \"ChangeMe\"\n","SERVICE_CREDENTIAL_KEY_NAME_SERVICE_PRINCIPAL = \"ChangeMe\"\n","\n","tables = [\"ChangeMe\",\"ChangeMe\",\"ChangeMe\"]\n","interval = 15\n","days_ago = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1122441b-403f-4b16-8ed5-618a59bc5d7f","showTitle":false,"title":""}},"outputs":[],"source":["# Imports\n","import pandas as pd\n","from azure.storage.filedatalake import DataLakeServiceClient\n","from azure.core._match_conditions import MatchConditions\n","from azure.storage.filedatalake._models import ContentSettings\n","from datetime import datetime, timedelta\n","import requests\n","import hashlib\n","import hmac\n","import base64\n","import logging\n","import urllib3\n","import json\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2f201c6a-8e0f-4e42-852b-20a220de659b","showTitle":false,"title":""}},"outputs":[],"source":["def initialize_storage_account(storage_account_name, storage_account_key):\n","    \n","    try:  \n","        global service_client\n","\n","        service_client = DataLakeServiceClient(account_url=f\"{'https'}://{storage_account_name}.dfs.core.windows.net\",\n","                                               credential=storage_account_key)\n","    \n","    except Exception as e:\n","        print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c7040ce9-e488-4377-9641-87f4cf6f89d6","showTitle":false,"title":""}},"outputs":[],"source":["# Unmount storage account containers. \n","for table_name in tables:\n","  unmount = \"/mnt/{0}/{1}\".format(STORAGE_ACCOUNT,\"export-{}\".format(table_name.lower()))\n","  \n","  try:\n","    dbutils.fs.unmount(unmount)\n","  except Exception as e:\n","        print(e)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"67712552-e01f-4650-ac67-942f9c4dd368","showTitle":false,"title":""}},"outputs":[],"source":["service_credential_key_name = SERVICE_CREDENTIAL_KEY_NAME_DATALAKE\n","\n","configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n","          \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n","          \"fs.azure.account.oauth2.client.id\": AAD_APPID,\n","          \"fs.azure.account.oauth2.client.secret\": dbutils.secrets.get(scope=SCOPE_NAME,key=service_credential_key_name),\n","          \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/{}/oauth2/token\".format(TENANT_ID)}\n","\n","# Re-Mount storage account containers. \n","for table_name in tables:\n","  storagecontainerNameExport  =  \"export-{}\".format(table_name.lower())\n","  mount_point_var_export      = f\"/mnt/{STORAGE_ACCOUNT}/{storagecontainerNameExport}\"\n","  try:\n","    dbutils.fs.mount( \n","        source = f\"abfss://{storagecontainerNameExport}@{STORAGE_ACCOUNT}.dfs.core.windows.net/\", \n","        mount_point = mount_point_var_export, \n","        extra_configs = configs)\n","  except ExecutionError as e:\n","    print (e)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5323713c-4ddc-4838-9191-16757504181f","showTitle":false,"title":""}},"outputs":[],"source":["def time_hop_generator(start_time,days_ago,interval):\n","  '''\n","  This generator recieves a start time(datatime), number of days(int) and time interval(minutes) string.\n","  Yields earliest and latest times for each interval.\n","  '''\n","  \n","  loop_count = int(days_ago * 24 * (60/interval))\n","  for i in range(0, loop_count):\n","    latest = start_time - timedelta(minutes=(interval * i))\n","    earliest = start_time - timedelta(minutes=(interval * (i+1)))\n","    yield (earliest, latest)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7365abba-57cc-407f-9b40-f59e4c0a18e3","showTitle":false,"title":""}},"outputs":[],"source":["def get_file_path(start_time):\n","  '''This function recieves a pandas timestamp object\n","     Returns the formatted data path'''\n","  year = str(start_time.year)\n","   \n","  # Month case.\n","  if(start_time.month < 10):\n","    month = \"0\" + str(start_time.month)\n","  else:\n","    month = str(start_time.month)\n","   \n","  # Day case.\n","  if(start_time.day < 10):\n","    day = \"0\" + str(start_time.day)\n","  else:\n","    day = str(start_time.day)\n","  \n","  # Hour case.\n","  if(start_time.hour < 10):\n","    hour = \"0\" + str(start_time.hour)\n","  else:\n","    hour = str(start_time.hour)\n","  return f\"y={year}/m={month}/d={day}/h={hour}\""]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"106a88a8-ea73-42b9-9aa6-b868e005ea58","showTitle":false,"title":""}},"outputs":[],"source":["def get_token(tenant, sp_id, sp_secret):\n","    \"\"\"Obtain authentication token using a Service Principal\"\"\"\n","    login_url = \"https://login.microsoftonline.com/\"+tenant+\"/oauth2/token\"\n","    resource = \"https://api.loganalytics.io\"\n","\n","    payload = {\n","        'grant_type': 'client_credentials',\n","        'client_id': sp_id,\n","        'client_secret': sp_secret,\n","        'Content-Type': 'x-www-form-urlencoded',\n","        'resource': resource\n","    }\n","    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","    try:\n","        response = requests.post(login_url, data=payload, verify=False)\n","        \n","    except Exception as error:\n","        logging.error(error)\n","    \n","    if (response.status_code >= 200 and response.status_code <= 299):\n","        logging.info('Token obtained')\n","        token = json.loads(response.content)[\"access_token\"]\n","        return {\"Authorization\": str(\"Bearer \"+ token)}\n","    else:\n","        logging.error(\"Unable to Read: \" + format(response.status_code))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"0b081b74-e8d4-433b-9fa2-b6dd805dc309","showTitle":false,"title":""}},"outputs":[],"source":["def get_data(query, token, azure_log_customer_id):\n","    \"\"\"Executes a KQL on a Azure Log Analytics Workspace\n","    \n","    Keyword arguments:\n","    query -- Kusto query to execute on Azure Log Analytics\n","    token -- Authentication token generated using get_token\n","    azure_log_customer_id -- Workspace ID obtained from Advanced Settings\n","    \"\"\"\n","    \n","    az_url = \"https://api.loganalytics.io/v1/workspaces/\"+ azure_log_customer_id + \"/query\"\n","    query = {\"query\": query}\n","\n","    try:\n","        response = requests.get(az_url, params=query, headers=token)\n","    except Exception as error:\n","        logging.error(error)\n","    \n","    if (response.status_code >= 200 and response.status_code <= 299):\n","        logging.info('Query ran successfully')\n","        return response\n","      \n","    else:\n","        logging.error(\"Unable to Read: \" + format(response.status_code))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"fb3f5f75-18b7-444b-9edd-fb08fe579248","showTitle":false,"title":""}},"outputs":[],"source":["def response_to_dataframe(response):\n","  \"\"\"\n","  \"\"\"\n","  response_json = response.json()\n","  formated_data = response_json['tables'][0]\n","  rows, columns = formated_data['rows'], formated_data['columns']\n","  df = pd.DataFrame(rows, columns=[col[\"name\"] for col in columns])\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"624b209a-5f47-4bbe-81db-b441a1112c39","showTitle":false,"title":""}},"outputs":[],"source":["def export_table(table_name,days_ago):\n","  '''\n","  This function recieves table name and number of days ago. \n","  Exports the data to a storage account.\n","  '''\n","  service_credential_key_name_sp = SERVICE_CREDENTIAL_KEY_NAME_SERVICE_PRINCIPAL \n","  service_credential_key_name_sa = SERVICE_CREDENTIAL_KEY_NAME_STORAGE_KEY\n","  storage_account_key = dbutils.secrets.get(scope=SCOPE_NAME,key=service_credential_key_name_sa)\n","  aad_appkey = dbutils.secrets.get(scope=SCOPE_NAME,key=service_credential_key_name_sp)\n","  container_name = \"export-{}\".format(table_name.lower())\n","  \n","  initialize_storage_account(STORAGE_ACCOUNT, storage_account_key)\n","  sp_token = get_token(TENANT_ID, sp_id=AAD_APPID, sp_secret=aad_appkey)\n","  file_system_client = service_client.get_file_system_client(file_system=container_name)\n"," \n","  now = datetime.now()\n","  start_time = datetime(now.year, now.month, now.day, 00, 00, 00, 00000)\n","  time_hops = time_hop_generator(start_time,days_ago,interval)\n","  \n","  # Export the data for every time interval per table.\n","  for time_hop in time_hops:\n","    query = f\"\"\"{table_name} | where TimeGenerated between (todatetime('{time_hop[0]}') .. todatetime('{time_hop[1]}'))\"\"\"\n","    response = get_data(query=query,token=sp_token, azure_log_customer_id=WORKSPACE_ID)\n","    df = response_to_dataframe(response)\n","    start_time = pd.to_datetime(df['TimeGenerated'].min(),infer_datetime_format=True)\n","    directory_client = file_system_client.get_directory_client(get_file_path(start_time))\n","   \n","    # Check if not empty.\n","    if df.empty:\n","      continue\n","    \n","    try:\n","      directory_client.create_file(f\"df_{start_time}\")\n","      df.to_parquet(f\"/dbfs/mnt/{STORAGE_ACCOUNT}/{container_name}/{get_file_path(start_time)}/df_{start_time}\", index=False)\n","     \n","    except Exception as e:\n","       print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1d895081-e5df-40e2-bcab-45f6b963596f","showTitle":false,"title":""}},"outputs":[],"source":["# Exporting the tables.\n","for table_name in tables:\n","  export_table(table_name,days_ago)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1bddd1a5-27f2-42e8-8c88-096b47d011fd","showTitle":false,"title":""}},"outputs":[],"source":["## Reading the data.\n","# testing_df = spark.read.option(\"header\",True) \\\n","#      .parquet(f\"/mnt/{STORAGE_ACCOUNT}/export-{tables[0]}/y=2022/m=09/d=10/*\")\n","# testing_df.limit(20).toPandas()"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"GetYourDataOut","notebookOrigID":3673425014641659,"widgets":{}},"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.2"},"vscode":{"interpreter":{"hash":"0b7ece93447ac0370c482399fb756ca235c878c6a78d0c41af9b03fce94c2296"}}},"nbformat":4,"nbformat_minor":0}
